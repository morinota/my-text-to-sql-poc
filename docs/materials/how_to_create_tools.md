# How to create tools | ğŸ¦œï¸ğŸ”— LangChain

# ãƒ„ãƒ¼ãƒ«ã®ä½œæˆæ–¹æ³• | ğŸ¦œï¸ğŸ”— LangChain

When constructing an agent, you will need to provide it with a list of Tools that it can use.
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹éš›ã«ã¯ã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒä½¿ç”¨ã§ãã‚‹ãƒ„ãƒ¼ãƒ«ã®ãƒªã‚¹ãƒˆã‚’æä¾›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

Besides the actual function that is called, the Tool consists of several components:
å‘¼ã³å‡ºã•ã‚Œã‚‹å®Ÿéš›ã®é–¢æ•°ã«åŠ ãˆã¦ã€ãƒ„ãƒ¼ãƒ«ã¯ä»¥ä¸‹ã®ã„ãã¤ã‹ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§æ§‹æˆã•ã‚Œã¦ã„ã¾ã™ã€‚

| Attribute | Type | Description |
|-----------|------|-------------|
| name      | str  | Must be unique within a set of tools provided to an LLM or agent. |
| description | str | Describes what the tool does. Used as context by the LLM or agent. |
| args_schema | pydantic.BaseModel | Optional but recommended, and required if using callback handlers. It can be used to provide more information (e.g., few-shot examples) or validation for expected parameters. |
| return_direct | boolean | Only relevant for agents. When True, after invoking the given tool, the agent will stop and return the result directly to the user. |

LangChain supports the creation of tools from:  
LangChainã¯ã€ä»¥ä¸‹ã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã®ä½œæˆã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ï¼š

- Functions;
- Functions;
- LangChain Runnables;
- LangChain Runnables;
- By sub-classing from BaseTool -- This is the most flexible method, it provides the largest degree of control, at the expense of more effort and code.  
- BaseToolã‹ã‚‰ã®ã‚µãƒ–ã‚¯ãƒ©ã‚¹åŒ– -- ã“ã‚Œã¯æœ€ã‚‚æŸ”è»Ÿãªæ–¹æ³•ã§ã‚ã‚Šã€æœ€å¤§ã®åˆ¶å¾¡ã‚’æä¾›ã—ã¾ã™ãŒã€ã‚ˆã‚Šå¤šãã®åŠ´åŠ›ã¨ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦ã§ã™ã€‚

Creating tools from functions may be sufficient for most use cases, and can be done via a simple @tool decorator.
é–¢æ•°ã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã™ã‚‹ã“ã¨ã¯ã€ã»ã¨ã‚“ã©ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã«å¯¾ã—ã¦ååˆ†ã§ã‚ã‚Šã€ã‚·ãƒ³ãƒ—ãƒ«ãª@toolãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½¿ç”¨ã—ã¦è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚

If more configuration is needed-- e.g., specification of both sync and async implementations-- one can also use the StructuredTool.from_function class method.
ã‚ˆã‚Šå¤šãã®è¨­å®šãŒå¿…è¦ãªå ´åˆï¼ˆä¾‹ãˆã°ã€åŒæœŸãŠã‚ˆã³éåŒæœŸã®å®Ÿè£…ã®ä¸¡æ–¹ã®ä»•æ§˜ãªã©ï¼‰ã€StructuredTool.from_functionã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

In this guide we provide an overview of these methods.
ã“ã®ã‚¬ã‚¤ãƒ‰ã§ã¯ã€ã“ã‚Œã‚‰ã®æ–¹æ³•ã®æ¦‚è¦ã‚’æä¾›ã—ã¾ã™ã€‚

tip: Models will perform better if the tools have well chosen names, descriptions and JSON schemas.
ãƒ’ãƒ³ãƒˆ: ãƒ„ãƒ¼ãƒ«ã«é©åˆ‡ã«é¸ã°ã‚ŒãŸåå‰ã€èª¬æ˜ã€ãŠã‚ˆã³JSONã‚¹ã‚­ãƒ¼ãƒãŒã‚ã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãŒå‘ä¸Šã—ã¾ã™ã€‚

## Creating tools from functions

## é–¢æ•°ã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã™ã‚‹

### @tool decorator

### @toolãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼

This @tool decorator is the simplest way to define a custom tool.
ã“ã®@toolãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©ã™ã‚‹æœ€ã‚‚ç°¡å˜ãªæ–¹æ³•ã§ã™ã€‚

The decorator uses the function name as the tool name by default, but this can be overridden by passing a string as the first argument.
ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é–¢æ•°åã‚’ãƒ„ãƒ¼ãƒ«åã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ãŒã€æœ€åˆã®å¼•æ•°ã¨ã—ã¦æ–‡å­—åˆ—ã‚’æ¸¡ã™ã“ã¨ã§ä¸Šæ›¸ãã§ãã¾ã™ã€‚

Additionally, the decorator will use the function's docstring as the tool's description - so a docstring MUST be provided.
ã•ã‚‰ã«ã€ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã¯é–¢æ•°ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–‡å­—åˆ—ã‚’ãƒ„ãƒ¼ãƒ«ã®èª¬æ˜ã¨ã—ã¦ä½¿ç”¨ã—ã¾ã™ - ã—ãŸãŒã£ã¦ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–‡å­—åˆ—ã¯å¿…ãšæä¾›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
from langchain_core.tools import tool

@tool
def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

# Let's inspect some of the attributes associated with the tool.
print(multiply.name)
print(multiply.description)
print(multiply.args)
```

API Reference: tool
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: tool

```python
multiply
```

Multiply two numbers.
2ã¤ã®æ•°ã‚’æ›ã‘ç®—ã—ã¾ã™ã€‚

```python
{'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}
```

Or create an async implementation, like this:
ã¾ãŸã€æ¬¡ã®ã‚ˆã†ã«éåŒæœŸå®Ÿè£…ã‚’ä½œæˆã§ãã¾ã™ï¼š

```python
from langchain_core.tools import tool

@tool
async def amultiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b
```

API Reference: tool
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: tool

Note that @tool supports parsing of annotations, nested schemas, and other features:
@toolã¯ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã€ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚¹ã‚­ãƒ¼ãƒã€ãŠã‚ˆã³ãã®ä»–ã®æ©Ÿèƒ½ã®è§£æã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã“ã¨ã«æ³¨æ„ã—ã¦ãã ã•ã„ï¼š

```python
from typing import Annotated, List

@tool
def multiply_by_max(
    a: Annotated[str, "scale factor"],
    b: Annotated[List[int], "list of ints over which to take maximum"],
) -> int:
    """Multiply a by the maximum of b."""
    return a * max(b)
```

```python
multiply_by_max.args_schema.schema()
```

```json
{
    'description': 'Multiply a by the maximum of b.',
    'properties': {
        'a': {'description': 'scale factor', 'title': 'A', 'type': 'string'},
        'b': {'description': 'list of ints over which to take maximum', 'items': {'type': 'integer'}, 'title': 'B', 'type': 'array'}
    },
    'required': ['a', 'b'],
    'title': 'multiply_by_maxSchema',
    'type': 'object'
}
```

You can also customize the tool name and JSON args by passing them into the tool decorator.
ãƒ„ãƒ¼ãƒ«åã¨JSONå¼•æ•°ã‚’ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã™ã‚‹ãŸã‚ã«ã€ãƒ„ãƒ¼ãƒ«ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã«æ¸¡ã™ã“ã¨ã‚‚ã§ãã¾ã™ã€‚

```python
from pydantic import BaseModel, Field

class CalculatorInput(BaseModel):
    a: int = Field(description="first number")
    b: int = Field(description="second number")

@tool("multiplication-tool", args_schema=CalculatorInput, return_direct=True)
def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

# Let's inspect some of the attributes associated with the tool.
print(multiply.name)
print(multiply.description)
print(multiply.args)
print(multiply.return_direct)
```

```python
multiplication-tool
```

Multiply two numbers.
2ã¤ã®æ•°ã‚’æ›ã‘ç®—ã—ã¾ã™ã€‚

```python
{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}
```

True

```python
True
```

### Docstring parsing

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–‡å­—åˆ—ã®è§£æ

@tool can optionally parse Google Style docstrings and associate the docstring components (such as arg descriptions) to the relevant parts of the tool schema.
@toolã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§Googleã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–‡å­—åˆ—ã‚’è§£æã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–‡å­—åˆ—ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆå¼•æ•°ã®èª¬æ˜ãªã©ï¼‰ã‚’ãƒ„ãƒ¼ãƒ«ã‚¹ã‚­ãƒ¼ãƒã®é–¢é€£éƒ¨åˆ†ã«é–¢é€£ä»˜ã‘ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

To toggle this behavior, specify parse_docstring:
ã“ã®å‹•ä½œã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã«ã¯ã€parse_docstringã‚’æŒ‡å®šã—ã¾ã™ï¼š

```python
@tool(parse_docstring=True)
def foo(bar: str, baz: int) -> str:
    """The foo.
    Args:
        bar: The bar.
        baz: The baz.
    """
    return bar
```

```python
foo.args_schema.schema()
```

```json
{
    'description': 'The foo.',
    'properties': {
        'bar': {'description': 'The bar.', 'title': 'Bar', 'type': 'string'},
        'baz': {'description': 'The baz.', 'title': 'Baz', 'type': 'integer'}
    },
    'required': ['bar', 'baz'],
    'title': 'fooSchema',
    'type': 'object'
}
```

### caution

### æ³¨æ„

By default, @tool(parse_docstring=True) will raise ValueError if the docstring does not parse correctly.
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ã€@tool(parse_docstring=True)ã¯ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³æ–‡å­—åˆ—ãŒæ­£ã—ãè§£æã•ã‚Œãªã„å ´åˆã€ValueErrorã‚’ç™ºç”Ÿã•ã›ã¾ã™ã€‚

See API Reference for detail and examples.
è©³ç´°ã¨ä¾‹ã«ã¤ã„ã¦ã¯APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚

### StructuredTool

### StructuredTool

The StructuredTool.from_function class method provides a bit more configurability than the @tool decorator, without requiring much additional code.
StructuredTool.from_functionã‚¯ãƒ©ã‚¹ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€@toolãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚ˆã‚Šã‚‚å°‘ã—å¤šãã®è¨­å®šã‚’æä¾›ã—ã¾ã™ãŒã€è¿½åŠ ã®ã‚³ãƒ¼ãƒ‰ã¯ã»ã¨ã‚“ã©å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚

```python
from langchain_core.tools import StructuredTool

def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

async def amultiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

calculator = StructuredTool.from_function(func=multiply, coroutine=amultiply)

print(calculator.invoke({"a": 2, "b": 3}))
print(await calculator.ainvoke({"a": 2, "b": 5}))
```

API Reference: StructuredTool
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: StructuredTool

To configure it:
è¨­å®šã™ã‚‹ã«ã¯ï¼š

```python
class CalculatorInput(BaseModel):
    a: int = Field(description="first number")
    b: int = Field(description="second number")

def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

calculator = StructuredTool.from_function(
    func=multiply,
    name="Calculator",
    description="multiply numbers",
    args_schema=CalculatorInput,
    return_direct=True,
    # coroutine= ... <- you can specify an async method if desired as well
)

print(calculator.invoke({"a": 2, "b": 3}))
print(calculator.name)
print(calculator.description)
print(calculator.args)
```

```python
Calculator
```

multiply numbers
æ•°ã‚’æ›ã‘ç®—ã—ã¾ã™ã€‚

```python
{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}
```

### Creating tools from Runnables

### Runnablesã‹ã‚‰ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã™ã‚‹

LangChain Runnables that accept string or dict input can be converted to tools using the as_tool method, which allows for the specification of names, descriptions, and additional schema information for arguments.
æ–‡å­—åˆ—ã¾ãŸã¯è¾æ›¸å…¥åŠ›ã‚’å—ã‘å…¥ã‚Œã‚‹LangChain Runnablesã¯ã€as_toolãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ãƒ„ãƒ¼ãƒ«ã«å¤‰æ›ã§ãã€åå‰ã€èª¬æ˜ã€ãŠã‚ˆã³å¼•æ•°ã®è¿½åŠ ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±ã‚’æŒ‡å®šã§ãã¾ã™ã€‚

Example usage:
ä½¿ç”¨ä¾‹ï¼š

```python
from langchain_core.language_models import GenericFakeChatModel
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages(
    [("human", "Hello. Please respond in the style of {answer_style}.")]
)

# Placeholder LLM
llm = GenericFakeChatModel(messages=iter(["hello matey"]))
chain = prompt | llm | StrOutputParser()

as_tool = chain.as_tool(
    name="Style responder", description="Description of when to use tool."
)

as_tool.args
```

API Reference: GenericFakeChatModel | StrOutputParser | ChatPromptTemplate
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: GenericFakeChatModel | StrOutputParser | ChatPromptTemplate

```python
/var/folders/4j/2rz3865x6qg07tx43146py8h0000gn/T/ipykernel_95770/2548361071.py:14: LangChainBetaWarning: This API is in beta and may change in the future.  as_tool = chain.as_tool(
```

```python
{'answer_style': {'title': 'Answer Style', 'type': 'string'}}
```

See this guide for more detail.
ã“ã®ã‚¬ã‚¤ãƒ‰ã§è©³ç´°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

### Subclass BaseTool

### BaseToolã‚’ã‚µãƒ–ã‚¯ãƒ©ã‚¹åŒ–ã™ã‚‹

You can define a custom tool by sub-classing from BaseTool.
BaseToolã‹ã‚‰ã‚µãƒ–ã‚¯ãƒ©ã‚¹åŒ–ã™ã‚‹ã“ã¨ã§ã€ã‚«ã‚¹ã‚¿ãƒ ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©ã§ãã¾ã™ã€‚

This provides maximal control over the tool definition, but requires writing more code.
ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ„ãƒ¼ãƒ«å®šç¾©ã«å¯¾ã™ã‚‹æœ€å¤§ã®åˆ¶å¾¡ãŒæä¾›ã•ã‚Œã¾ã™ãŒã€ã‚ˆã‚Šå¤šãã®ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
from typing import Optional, Type
from langchain_core.callbacks import (
    AsyncCallbackManagerForToolRun,
    CallbackManagerForToolRun,
)
from langchain_core.tools import BaseTool
from pydantic import BaseModel, Field

class CalculatorInput(BaseModel):
    a: int = Field(description="first number")
    b: int = Field(description="second number")

# Note: It's important that every field has type hints. BaseTool is a
# Pydantic class and not having type hints can lead to unexpected behavior.
class CustomCalculatorTool(BaseTool):
    name: str = "Calculator"
    description: str = "useful for when you need to answer questions about math"
    args_schema: Type[BaseModel] = CalculatorInput
    return_direct: bool = True

    def _run(
        self, a: int, b: int, run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """Use the tool."""
        return a * b

    async def _arun(
        self,
        a: int,
        b: int,
        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
    ) -> str:
        """Use the tool asynchronously."""
        return self._run(a, b, run_manager=run_manager.get_sync())
```

API Reference: AsyncCallbackManagerForToolRun | CallbackManagerForToolRun | BaseTool
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: AsyncCallbackManagerForToolRun | CallbackManagerForToolRun | BaseTool

```python
multiply = CustomCalculatorTool()
print(multiply.name)
print(multiply.description)
print(multiply.args)
print(multiply.return_direct)
print(multiply.invoke({"a": 2, "b": 3}))
print(await multiply.ainvoke({"a": 2, "b": 3}))
```

```python
Calculator
```

useful for when you need to answer questions about math
æ•°å­¦ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹å¿…è¦ãŒã‚ã‚‹ã¨ãã«ä¾¿åˆ©ã§ã™ã€‚

```python
{'a': {'description': 'first number', 'title': 'A', 'type': 'integer'}, 'b': {'description': 'second number', 'title': 'B', 'type': 'integer'}}
```

True

```python
True
```

66

```python
66
```

### How to create async tools

### éåŒæœŸãƒ„ãƒ¼ãƒ«ã®ä½œæˆæ–¹æ³•

LangChain Tools implement the Runnable interface ğŸƒ.
LangChainãƒ„ãƒ¼ãƒ«ã¯Runnableã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’å®Ÿè£…ã—ã¦ã„ã¾ã™ğŸƒã€‚

All Runnables expose the invoke and ainvoke methods (as well as other methods like batch, abatch, astream etc).
ã™ã¹ã¦ã®Runnableã¯invokeãŠã‚ˆã³ainvokeãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆãŠã‚ˆã³batchã€abatchã€astreamãªã©ã®ä»–ã®ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰ã‚’å…¬é–‹ã—ã¾ã™ã€‚

So even if you only provide a sync implementation of a tool, you could still use the ainvoke interface, but there are some important things to know:
ã—ãŸãŒã£ã¦ã€ãƒ„ãƒ¼ãƒ«ã®åŒæœŸå®Ÿè£…ã®ã¿ã‚’æä¾›ã—ã¦ã‚‚ã€ainvokeã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã§ãã¾ã™ãŒã€çŸ¥ã£ã¦ãŠãã¹ãé‡è¦ãªã“ã¨ãŒã‚ã‚Šã¾ã™ï¼š

LangChain's by default provides an async implementation that assumes that the function is expensive to compute, so it'll delegate execution to another thread.
LangChainã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã€é–¢æ•°ã®è¨ˆç®—ã«ã‚³ã‚¹ãƒˆãŒã‹ã‹ã‚‹ã¨ä»®å®šã—ã¦éåŒæœŸå®Ÿè£…ã‚’æä¾›ã—ã¦ãŠã‚Šã€ãã®ãŸã‚ã€å®Ÿè¡Œã‚’åˆ¥ã®ã‚¹ãƒ¬ãƒƒãƒ‰ã«å§”ä»»ã—ã¾ã™ã€‚

If you're working in an async codebase, you should create async tools rather than sync tools, to avoid incurring a small overhead due to that thread.
éåŒæœŸã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§ä½œæ¥­ã—ã¦ã„ã‚‹å ´åˆã¯ã€ãã®ã‚¹ãƒ¬ãƒƒãƒ‰ã«ã‚ˆã‚‹ã‚ãšã‹ãªã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ã‚’å›é¿ã™ã‚‹ãŸã‚ã«ã€åŒæœŸãƒ„ãƒ¼ãƒ«ã§ã¯ãªãéåŒæœŸãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python

If you need both sync and async implementations, use StructuredTool.from_function or sub-class from BaseTool.
åŒæœŸãŠã‚ˆã³éåŒæœŸã®ä¸¡æ–¹ã®å®Ÿè£…ãŒå¿…è¦ãªå ´åˆã¯ã€StructuredTool.from_functionã‚’ä½¿ç”¨ã™ã‚‹ã‹ã€BaseToolã‹ã‚‰ã‚µãƒ–ã‚¯ãƒ©ã‚¹åŒ–ã—ã¦ãã ã•ã„ã€‚

If implementing both sync and async, and the sync code is fast to run, override the default LangChain async implementation and simply call the sync code.
åŒæœŸã¨éåŒæœŸã®ä¸¡æ–¹ã‚’å®Ÿè£…ã™ã‚‹å ´åˆã€ã‹ã¤åŒæœŸã‚³ãƒ¼ãƒ‰ãŒé«˜é€Ÿã§å®Ÿè¡Œã•ã‚Œã‚‹å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®LangChainéåŒæœŸå®Ÿè£…ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰ã—ã€å˜ã«åŒæœŸã‚³ãƒ¼ãƒ‰ã‚’å‘¼ã³å‡ºã—ã¦ãã ã•ã„ã€‚

You CANNOT and SHOULD NOT use the sync invoke with an async tool.
éåŒæœŸãƒ„ãƒ¼ãƒ«ã«å¯¾ã—ã¦åŒæœŸinvokeã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã¯ã§ããšã€ä½¿ç”¨ã™ã¹ãã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

```python
from langchain_core.tools import StructuredTool

def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

calculator = StructuredTool.from_function(func=multiply)

print(calculator.invoke({"a": 2, "b": 3}))
print(await calculator.ainvoke({"a": 2, "b": 5}))  # Uses default LangChain async implementation incurs small overhead
```

API Reference: StructuredTool
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: StructuredTool

```python
610
```

```python
610
```

```python
from langchain_core.tools import StructuredTool

def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

async def amultiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

calculator = StructuredTool.from_function(func=multiply, coroutine=amultiply)

print(calculator.invoke({"a": 2, "b": 3}))
print(await calculator.ainvoke({"a": 2, "b": 5}))  # Uses use provided amultiply without additional overhead
```

API Reference: StructuredTool
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: StructuredTool

```python
610
```

```python
610
```

You should not and cannot use .invoke when providing only an async definition.
éåŒæœŸå®šç¾©ã®ã¿ã‚’æä¾›ã™ã‚‹å ´åˆã€.invokeã‚’ä½¿ç”¨ã™ã¹ãã§ã¯ãªãã€ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚

```python
@tool
async def multiply(a: int, b: int) -> int:
    """Multiply two numbers."""
    return a * b

try:
    multiply.invoke({"a": 2, "b": 3})
except NotImplementedError:
    print("Raised not implemented error. You should not be doing this.")
```

Raised not implemented error. You should not be doing this.

```python
å®Ÿè£…ã•ã‚Œã¦ã„ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã“ã‚Œã‚’è¡Œã†ã¹ãã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
```

### Handling Tool Errors

### ãƒ„ãƒ¼ãƒ«ã‚¨ãƒ©ãƒ¼ã®å‡¦ç†

If you're using tools with agents, you will likely need an error handling strategy, so the agent can recover from the error and continue execution.
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹å ´åˆã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒã‚¨ãƒ©ãƒ¼ã‹ã‚‰å›å¾©ã—ã€å®Ÿè¡Œã‚’ç¶šã‘ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ã€ã‚¨ãƒ©ãƒ¼å‡¦ç†æˆ¦ç•¥ãŒå¿…è¦ã«ãªã‚‹ã§ã—ã‚‡ã†ã€‚

A simple strategy is to throw a ToolException from inside the tool and specify an error handler using handle_tool_error.
ã‚·ãƒ³ãƒ—ãƒ«ãªæˆ¦ç•¥ã¯ã€ãƒ„ãƒ¼ãƒ«å†…ã‹ã‚‰ToolExceptionã‚’ã‚¹ãƒ­ãƒ¼ã—ã€handle_tool_errorã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã™ã€‚

When the error handler is specified, the exception will be caught and the error handler will decide which output to return from the tool.
ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒæŒ‡å®šã•ã‚Œã‚‹ã¨ã€ä¾‹å¤–ãŒã‚­ãƒ£ãƒƒãƒã•ã‚Œã€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ãŒãƒ„ãƒ¼ãƒ«ã‹ã‚‰è¿”ã™å‡ºåŠ›ã‚’æ±ºå®šã—ã¾ã™ã€‚

You can set handle_tool_error to True, a string value, or a function.
handle_tool_errorã‚’Trueã€æ–‡å­—åˆ—å€¤ã€ã¾ãŸã¯é–¢æ•°ã«è¨­å®šã§ãã¾ã™ã€‚

If it's a function, the function should take a ToolException as a parameter and return a value.
é–¢æ•°ã®å ´åˆã€ãã®é–¢æ•°ã¯ToolExceptionã‚’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦å—ã‘å–ã‚Šã€å€¤ã‚’è¿”ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

Please note that only raising a ToolException won't be effective.
ToolExceptionã‚’ã‚¹ãƒ­ãƒ¼ã™ã‚‹ã ã‘ã§ã¯åŠ¹æœãŒã‚ã‚Šã¾ã›ã‚“ã€‚

You need to first set the handle_tool_error of the tool because its default value is False.
ãƒ„ãƒ¼ãƒ«ã®handle_tool_errorã‚’æœ€åˆã«è¨­å®šã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¯Falseã§ã™ã€‚

```python
from langchain_core.tools import ToolException

def get_weather(city: str) -> int:
    """Get weather for the given city."""
    raise ToolException(f"Error: There is no city by the name of {city}.")
```

API Reference: ToolException
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: ToolException

Here's an example with the default handle_tool_error=True behavior.
ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®handle_tool_error=Trueã®å‹•ä½œã®ä¾‹ã§ã™ã€‚

```python
get_weather_tool = StructuredTool.from_function(
    func=get_weather,
    handle_tool_error=True,
)

get_weather_tool.invoke({"city": "foobar"})
```

```python
'Error: There is no city by the name of foobar.'
```

We can set handle_tool_error to a string that will always be returned.
handle_tool_errorã‚’å¸¸ã«è¿”ã•ã‚Œã‚‹æ–‡å­—åˆ—ã«è¨­å®šã§ãã¾ã™ã€‚

```python
get_weather_tool = StructuredTool.from_function(
    func=get_weather,
    handle_tool_error="There is no such city, but it's probably above 0K there!",
)

get_weather_tool.invoke({"city": "foobar"})
```

```python
"There is no such city, but it's probably above 0K there!"
```

Handling the error using a function:
é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’å‡¦ç†ã—ã¾ã™ï¼š

```python
def _handle_error(error: ToolException) -> str:
    return f"The following errors occurred during tool execution: `{error.args[0]}`"

get_weather_tool = StructuredTool.from_function(
    func=get_weather,
    handle_tool_error=_handle_error,
)

get_weather_tool.invoke({"city": "foobar"})
```

```python
'The following errors occurred during tool execution: `Error: There is no city by the name of foobar.`'
```

### Returning artifacts of Tool execution

### ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã®æˆæœç‰©ã‚’è¿”ã™

Sometimes there are artifacts of a tool's execution that we want to make accessible to downstream components in our chain or agent, but that we don't want to expose to the model itself.
æ™‚ã«ã¯ã€ãƒ„ãƒ¼ãƒ«ã®å®Ÿè¡Œã®æˆæœç‰©ãŒã‚ã‚Šã€ãã‚Œã‚’ãƒã‚§ãƒ¼ãƒ³ã‚„ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¸‹æµã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ã«ã—ãŸã„ãŒã€ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã«ã¯å…¬é–‹ã—ãŸããªã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

For example if a tool returns custom objects like Documents, we may want to pass some view or metadata about this output to the model without passing the raw output to the model.
ä¾‹ãˆã°ã€ãƒ„ãƒ¼ãƒ«ãŒDocumentsã®ã‚ˆã†ãªã‚«ã‚¹ã‚¿ãƒ ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™å ´åˆã€ãƒ¢ãƒ‡ãƒ«ã«ç”Ÿã®å‡ºåŠ›ã‚’æ¸¡ã•ãšã«ã€ã“ã®å‡ºåŠ›ã«é–¢ã™ã‚‹ãƒ“ãƒ¥ãƒ¼ã‚„ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã—ãŸã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

At the same time, we may want to be able to access this full output elsewhere, for example in downstream tools.
åŒæ™‚ã«ã€ä»–ã®å ´æ‰€ã€ä¾‹ãˆã°ä¸‹æµã®ãƒ„ãƒ¼ãƒ«ã§ã“ã®å®Œå…¨ãªå‡ºåŠ›ã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„å ´åˆãŒã‚ã‚Šã¾ã™ã€‚

The Tool and ToolMessage interfaces make it possible to distinguish between the parts of the tool output meant for the model (this is the ToolMessage.content) and those parts which are meant for use outside the model (ToolMessage.artifact).
ToolãŠã‚ˆã³ToolMessageã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¯ã€ãƒ„ãƒ¼ãƒ«å‡ºåŠ›ã®ãƒ¢ãƒ‡ãƒ«å‘ã‘ã®éƒ¨åˆ†ï¼ˆã“ã‚Œã¯ToolMessage.contentã§ã™ï¼‰ã¨ã€ãƒ¢ãƒ‡ãƒ«å¤–ã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã®éƒ¨åˆ†ï¼ˆToolMessage.artifactï¼‰ã‚’åŒºåˆ¥ã™ã‚‹ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚

Requires langchain-core >= 0.2.19
ã“ã®æ©Ÿèƒ½ã¯langchain-core == 0.2.19ã§è¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæœ€æ–°ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

If we want our tool to distinguish between message content and other artifacts, we need to specify response_format="content_and_artifact" when defining our tool and make sure that we return a tuple of (content, artifact):
ãƒ„ãƒ¼ãƒ«ãŒãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨ä»–ã®æˆæœç‰©ã‚’åŒºåˆ¥ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã«ã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’å®šç¾©ã™ã‚‹éš›ã«response_format="content_and_artifact"ã‚’æŒ‡å®šã—ã€(content, artifact)ã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™ã‚ˆã†ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
import random
from typing import List, Tuple
from langchain_core.tools import tool

@tool(response_format="content_and_artifact")
def generate_random_ints(min: int, max: int, size: int) -> Tuple[str, List[int]]:
    """Generate size random ints in the range [min, max]."""
    array = [random.randint(min, max) for _ in range(size)]
    content = f"Successfully generated array of {size} random ints in [{min}, {max}]."
    return content, array
```

API Reference: tool
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: tool

If we invoke our tool directly with the tool arguments, we'll get back just the content part of the output:
ãƒ„ãƒ¼ãƒ«å¼•æ•°ã§ãƒ„ãƒ¼ãƒ«ã‚’ç›´æ¥å‘¼ã³å‡ºã™ã¨ã€å‡ºåŠ›ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„éƒ¨åˆ†ã®ã¿ãŒè¿”ã•ã‚Œã¾ã™ï¼š

```python
generate_random_ints.invoke({"min": 0, "max": 9, "size": 10})
```

```python
'Successfully generated array of 10 random ints in [0, 9].'
```

If we invoke our tool with a ToolCall (like the ones generated by tool-calling models), we'll get back a ToolMessage that contains both the content and artifact generated by the Tool:
ãƒ„ãƒ¼ãƒ«ã‚’ToolCallï¼ˆãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚Œã‚‹ã‚‚ã®ï¼‰ã§å‘¼ã³å‡ºã™ã¨ã€ãƒ„ãƒ¼ãƒ«ã«ã‚ˆã£ã¦ç”Ÿæˆã•ã‚ŒãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨æˆæœç‰©ã®ä¸¡æ–¹ã‚’å«ã‚€ToolMessageãŒè¿”ã•ã‚Œã¾ã™ï¼š

```python
generate_random_ints.invoke(
    {
        "name": "generate_random_ints",
        "args": {"min": 0, "max": 9, "size": 10},
        "id": "123",  # required
        "type": "tool_call",  # required
    }
)
```

```python
ToolMessage(content='Successfully generated array of 10 random ints in [0, 9].', name='generate_random_ints', tool_call_id='123', artifact=[4, 8, 2, 4, 1, 0, 9, 5, 8, 1])
```

We can do the same when subclassing BaseTool:
BaseToolã‚’ã‚µãƒ–ã‚¯ãƒ©ã‚¹åŒ–ã™ã‚‹éš›ã«ã‚‚åŒæ§˜ã®ã“ã¨ãŒã§ãã¾ã™ï¼š

```python
from langchain_core.tools import BaseTool

class GenerateRandomFloats(BaseTool):
    name: str = "generate_random_floats"
    description: str = "Generate size random floats in the range [min, max]."
    response_format: str = "content_and_artifact"
    ndigits: int = 2

    def _run(self, min: float, max: float, size: int) -> Tuple[str, List[float]]:
        range_ = max - min
        array = [
            round(min + (range_ * random.random()), ndigits=self.ndigits)
            for _ in range(size)
        ]
        content = f"Generated {size} floats in [{min}, {max}], rounded to {self.ndigits} decimals."
        return content, array

    # Optionally define an equivalent async method
    # async def _arun(self, min: float, max: float, size: int) -> Tuple[str, List[float]]:
    #     ...
```

API Reference: BaseTool
APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹: BaseTool

```python
rand_gen = GenerateRandomFloats(ndigits=4)

rand_gen.invoke(
    {
        "name": "generate_random_floats",
        "args": {"min": 0.1, "max": 3.3333, "size": 3},
        "id": "123",
        "type": "tool_call",
    }
)
```

```python
ToolMessage(content='Generated 3 floats in [0.1, 3.3333], rounded to 4 decimals.', name='generate_random_floats', tool_call_id='123', artifact=[1.5566, 0.5134, 2.7914])
```

Edit this page
ã“ã®ãƒšãƒ¼ã‚¸ã‚’ç·¨é›†

Was this page helpful?
ã“ã®ãƒšãƒ¼ã‚¸ã¯å½¹ã«ç«‹ã¡ã¾ã—ãŸã‹ï¼Ÿ

Previous
å‰

Custom Retriever
ã‚«ã‚¹ã‚¿ãƒ ãƒªãƒˆãƒªãƒ¼ãƒãƒ¼

Next
æ¬¡

How to debug your LLM apps
LLMã‚¢ãƒ—ãƒªã‚’ãƒ‡ãƒãƒƒã‚°ã™ã‚‹æ–¹æ³•

```
